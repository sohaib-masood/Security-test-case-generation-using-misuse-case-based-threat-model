import spacy
from spacy.tokens import Doc, Token
from spacy.matcher import PhraseMatcher

nlp = spacy.load("en_core_web_sm")

Token.set_extension("custom_pos", default=None, force=True)

custom_pronouns = ["MALICIOUS_USER"]

matcher = PhraseMatcher(nlp.vocab)
patterns = [nlp.make_doc(term) for term in custom_pronouns]
matcher.add("CUSTOM_PRONOUN", patterns)

doc = nlp(data)

matches = matcher(doc)
for match_id, start, end in matches:
    span = doc[start:end]
    for token in span:
        token.pos_ = "PRON"  
        token._.custom_pos = "PRON"  

print("Token | POS | Dependency")
print("-" * 30)
for token in doc:
    print(f"{token.text} | {token.pos_} | {token.dep_}")